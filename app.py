import streamlit as st
import asyncio
import os
from dotenv import load_dotenv

# ADK ë° Agent ê´€ë ¨ ì„í¬íŠ¸
from google.adk.agents import Agent
from google.adk.models.lite_llm import LiteLlm
from google.adk.sessions import InMemorySessionService
from google.adk.runners import Runner
from google.genai import types

from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings

# 1. ê¸°ë³¸ ì„¤ì • ë° API í‚¤ ë¡œë“œ
load_dotenv()

if not os.getenv("GOOGLE_API_KEY"):
    print("âŒ ì—ëŸ¬: .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
elif not os.getenv("OPENAI_API_KEY"):
    print("âŒ ì—ëŸ¬: .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ OPENAI_API_KEê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    print("âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ")

MODEL_GEMINI_2_0_FLASH = "gemini/gemini-2.0-flash"
MODEL_GPT_4O = "openai/gpt-4.1-mini"

st.set_page_config(page_title="BabySquad", page_icon="ğŸ‘¶")
st.title("ğŸ‘¶ BabySquad: AI ìœ¡ì•„ ì „ë¬¸ê°€ íŒ€")
st.caption("ğŸš€ 4ê°œì›” ì•„ê¸° ë¶€ëª¨ë¥¼ ìœ„í•œ ìˆ˜ë©´ & ì˜ì–‘ ë§ì¶¤ ì†”ë£¨ì…˜")

with st.sidebar:
    st.header("About BabySquad")
    st.markdown("""
    - ğŸ‘©â€ğŸ’¼ **Head Nanny:** íŒ€ì¥
    - ğŸ’¤ **Sleep Expert:** ìˆ˜ë©´ ì „ë¬¸ê°€
    - ğŸ¥¦ **Nutritionist:** ì˜ì–‘ ì „ë¬¸ê°€
    """)
    if st.button("ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()

# ---------------------------------------------------------
# [2] ë²¡í„° DB ë¡œë“œ (Global Stateì— ì €ì¥)
# ---------------------------------------------------------
if "vector_store" not in st.session_state:
    if os.getenv("GOOGLE_API_KEY"):
        embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
        if os.path.exists("./chroma_db"):
            st.session_state.vector_store = Chroma(
                persist_directory="./chroma_db",
                embedding_function=embeddings,
                collection_name="baby_knowledge"
            )
            print("âœ… Vector DB Loaded into Session State")
        else:
            st.error("âš ï¸ 'chroma_db' í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ingest.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            st.session_state.vector_store = None
    else:
        st.error("API Keyê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.session_state.vector_store = None

# ---------------------------------------------------------
# 2. ì—ì´ì „íŠ¸ íŒ€ ì„¤ì • (ìºì‹± ì‚¬ìš©)
# ---------------------------------------------------------
@st.cache_resource
def setup_agent_system():
    # â˜…â˜…â˜… [í•µì‹¬] RAG ê²€ìƒ‰ ë„êµ¬ ì •ì˜ â˜…â˜…â˜…
    def search_knowledge_base(query: str) -> str:
        """
        ìœ¡ì•„ ê°€ì´ë“œ ë¬¸ì„œ(ìˆ˜ë©´, ì˜ì–‘ ë“±)ì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        ì§ˆë¬¸ì— ëŒ€í•œ êµ¬ì²´ì ì¸ í•´ê²°ì±…ì´ë‚˜ ìˆ˜ì¹˜ë¥¼ ì°¾ì„ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
        """
        # ì „ì—­ ì„¸ì…˜ ìƒíƒœì—ì„œ ê°€ì ¸ì˜´ (ìŠ¤ì½”í”„ ì—ëŸ¬ ë°©ì§€)
        db = st.session_state.get("vector_store")
        
        if db is None:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì§€ì‹ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
        print(f"ğŸ” ê²€ìƒ‰ ìˆ˜í–‰: {query}")
        try:
            # ìœ ì‚¬ë„ ê²€ìƒ‰ (ìƒìœ„ 7ê°œ ë¬¸ì„œ ì¶”ì¶œ)
            results = db.similarity_search(query, k=7)
            
            # [í•µì‹¬ ë³€ê²½] ë‚´ìš©ê³¼ í•¨ê»˜ ì¶œì²˜(Metadata)ë¥¼ í¬ë§·íŒ…í•´ì„œ í•©ì¹¨
            context_list = []
            for doc in results:
                # 1. íŒŒì¼ ê²½ë¡œì—ì„œ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ (ì˜ˆ: data/guide.pdf -> guide.pdf)
                source_path = doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ")
                file_name = os.path.basename(source_path) 
                
                # 2. í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì¶œ (0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ +1 í•´ì¤Œ)
                page_num = doc.metadata.get("page", 0) + 1
                
                # 3. í…ìŠ¤íŠ¸ êµ¬ì„±
                formatted_text = (
                    f"--- ë¬¸ì„œ ë‚´ìš© ---\n"
                    f"{doc.page_content}\n"
                    f"ğŸ‘‰ [ì¶œì²˜: {file_name}, {page_num}í˜ì´ì§€]"
                )
                context_list.append(formatted_text)

            context_text = "\n\n".join(context_list)
            # [ë””ë²„ê¹…ìš© ë¡œê·¸ ì¶”ê°€] í„°ë¯¸ë„ì—ì„œ ì´ ë¡œê·¸ê°€ ì°íˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!
            print(f"âœ… ë„êµ¬ ë°˜í™˜ê°’:\n{context_text}")
            return f"[ê²€ìƒ‰ëœ ê°€ì´ë“œë¼ì¸]\n{context_text}"
        except Exception as e:
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    # (1) ìˆ˜ë©´ ì „ë¬¸ê°€ (ì´ì œ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•¨)
    sleep_expert = Agent(
        name="sleep_expert",
        model=LiteLlm(model=MODEL_GPT_4O),
        description="ìˆ˜ë©´ ì „ë¬¸",
        instruction="""
        ë‹¹ì‹ ì€ ìˆ˜ë©´ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´ ë°˜ë“œì‹œ 'search_knowledge_base' ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ê°€ì´ë“œë¼ì¸ì„ ê²€ìƒ‰í•˜ì„¸ìš”.
        ê²€ìƒ‰ëœ ë‚´ìš©(ê¹¨ì‹œ, ìˆ˜ë©´ì˜ì‹ ë“±)ì„ ê¸°ë°˜ìœ¼ë¡œ ë”°ëœ»í•˜ê²Œ ì¡°ì–¸í•´ì£¼ì„¸ìš”.
        """,
        tools=[search_knowledge_base] # ê²€ìƒ‰ ë„êµ¬ ì¥ì°©!
    )
    
    # (2) ì˜ì–‘ ì „ë¬¸ê°€
    nutrition_expert = Agent(
        name="nutrition_expert",
        model=LiteLlm(model=MODEL_GPT_4O),
        description="ì˜ì–‘ ì „ë¬¸",
        instruction="""
        ë‹¹ì‹ ì€ ë”°ëœ»í•œ ìˆ˜ë©´ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ 'search_knowledge_base' ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì´ë“œë¼ì¸ì„ ê²€ìƒ‰í•˜ì„¸ìš”.
        
        [ì¤‘ìš” ê·œì¹™]
        1. ê²€ìƒ‰ëœ ë‚´ìš©ì— ìˆëŠ” **ì •ë³´ì™€ ìˆ˜ì¹˜**ë¥¼ ì •í™•í•˜ê²Œ ì „ë‹¬í•˜ì„¸ìš”.
        2. ë‹µë³€ì˜ ë§¨ ë§ˆì§€ë§‰ì—ëŠ” **ë„êµ¬ì—ì„œ ì œê³µí•œ ì¶œì²˜(íŒŒì¼ëª…, í˜ì´ì§€)**ë¥¼ ë°˜ë“œì‹œ ê·¸ëŒ€ë¡œ ëª…ì‹œí•˜ì„¸ìš”.
        3. ì¶œì²˜ í˜•ì‹: (ì¶œì²˜: íŒŒì¼ëª…, p.í˜ì´ì§€ë²ˆí˜¸)
        """,
        tools=[search_knowledge_base]
    )

    # (3) í—¤ë“œ ë‚´ë‹ˆ
    head_nanny = Agent(
        name="head_nanny",
        model=LiteLlm(model=MODEL_GPT_4O),
        sub_agents=[sleep_expert, nutrition_expert],
        description="ë©”ì¸ ìƒë‹´ì‚¬",
        instruction="BabySquad íŒ€ì¥ì…ë‹ˆë‹¤. ìˆ˜ë©´/ì˜ì–‘ ì „ë¬¸ê°€ë¥¼ ì ì ˆíˆ í˜¸ì¶œí•˜ê³ , ì¸ì‚¬ëŠ” ì§ì ‘ í•˜ì„¸ìš”."
    )
    
    # (3) ì„œë¹„ìŠ¤ ë° ëŸ¬ë„ˆ ìƒì„±
    session_service = InMemorySessionService()
    runner = Runner(agent=head_nanny, app_name="baby_squad_web", session_service=session_service)
    session_id = "rag_session_001"
        
    return runner, session_service, session_id

runner, session_service, session_id = setup_agent_system()

# ---------------------------------------------------------
# 3. ì±„íŒ… UI êµ¬í˜„
# ---------------------------------------------------------
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ìœ¡ì•„ ê³ ë¯¼ì´ ìˆìœ¼ì‹ ê°€ìš”? ìˆ˜ë©´ì´ë‚˜ ì´ìœ ì‹, ë¬´ì—‡ì´ë“  ë¬¼ì–´ë´ì£¼ì„¸ìš”. ğŸ˜Š"}
    ]

for msg in st.session_state.messages:
    avatar = "ğŸ§‘â€ğŸ¼" if msg["role"] == "user" else "ğŸ¤–"
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸ¼"):
        st.markdown(prompt)

    with st.chat_message("assistant", avatar="ğŸ¤–"):
        message_placeholder = st.empty()
        
        # with st.spinner("ì „ë¬¸ê°€ë“¤ì´ íšŒì˜ ì¤‘ì…ë‹ˆë‹¤..."):
        with st.spinner("ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ ë° ë¶„ì„ ì¤‘..."):
            # [ìˆ˜ì •ëœ ë¶€ë¶„] try-exceptë¡œ "ì´ë¯¸ ì¡´ì¬í•¨" ì—ëŸ¬ ë¬´ì‹œí•˜ê¸°
            async def run_agent():
                APP_NAME = "baby_squad_web"
                USER_ID = "rag_user"
                
                # 1. ì„¸ì…˜ ìƒì„± ì‹œë„ (ì´ë¯¸ ìˆìœ¼ë©´ ì—ëŸ¬ê°€ ë‚˜ë¯€ë¡œ try-exceptë¡œ ê°ìŒˆ)
                try:
                    # ì„¸ì…˜ ë§Œë“¤ê¸°ë¥¼ ì‹œë„í•©ë‹ˆë‹¤.
                    await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=session_id)
                except Exception:
                    # ì—ëŸ¬ê°€ ë‚˜ë©´ "ì•„, ì´ë¯¸ ì„¸ì…˜ì´ ìˆêµ¬ë‚˜" í•˜ê³  ê·¸ëƒ¥ ë„˜ì–´ê°‘ë‹ˆë‹¤.
                    pass 

                # 2. ì‹¤í–‰
                content = types.Content(role='user', parts=[types.Part(text=prompt)])
                result_text = "ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                
                async for event in runner.run_async(user_id=USER_ID, session_id=session_id, new_message=content):
                    if event.is_final_response():
                        if event.content and event.content.parts:
                            result_text = event.content.parts[0].text
                        break
                return result_text

            # Streamlit ë¹„ë™ê¸° ì‹¤í–‰
            try:
                response_text = asyncio.run(run_agent())
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                response_text = loop.run_until_complete(run_agent())
                loop.close()

        message_placeholder.markdown(response_text)
        st.session_state.messages.append({"role": "assistant", "content": response_text})