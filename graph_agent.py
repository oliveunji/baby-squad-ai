import os
import operator
from typing import Annotated, List, TypedDict, Union
from dotenv import load_dotenv

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from langchain_openai import ChatOpenAI
from langchain_google_genai import GoogleGenerativeAIEmbeddings # DB ê²€ìƒ‰ìš©
from langchain_chroma import Chroma
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver # ğŸ§  ê¸°ì–µë ¥ ëª¨ë“ˆ

# 1. í™˜ê²½ ì„¤ì •
load_dotenv()

# [ì¤‘ìš”] ëª¨ë¸ ì„¤ì •
# - ì¶”ë¡ /ëŒ€í™”: OpenAI (GPT-4o)
# - ì„ë² ë”©/ê²€ìƒ‰: Google (ê¸°ì¡´ DBì™€ í˜¸í™˜ì„± ìœ ì§€)
if not os.getenv("OPENAI_API_KEY") or not os.getenv("GOOGLE_API_KEY"):
    print("âŒ Error: API Keyê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. .envë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    exit()

llm = ChatOpenAI(model="gpt-4o", temperature=0)
embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")

# 2. ë²¡í„° DB ë¡œë“œ (ê¸°ì¡´ì— ë§Œë“  chroma_db í´ë”ê°€ ìˆì–´ì•¼ í•¨!)
if os.path.exists("./chroma_db"):
    vector_store = Chroma(
        persist_directory="./chroma_db",
        embedding_function=embeddings,
        collection_name="baby_knowledge"
    )
    print("âœ… RAG ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
else:
    vector_store = None
    print("âš ï¸ ê²½ê³ : chroma_db í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ingest.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")

# ---------------------------------------------------------
# [Step 1] ìƒíƒœ(State) ì •ì˜
# ---------------------------------------------------------
class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], operator.add]
    next: str

# ---------------------------------------------------------
# [Step 2] ë„êµ¬ í•¨ìˆ˜ (RAG ê²€ìƒ‰)
# ---------------------------------------------------------
def retrieve_knowledge(query: str, category: str) -> str:
    """DBì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•´ì„œ ë°˜í™˜"""
    if not vector_store:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì§€ì‹ DBê°€ ì—†ìŠµë‹ˆë‹¤."
    
    print(f"  ğŸ” [{category}] ë¬¸ì„œ ê²€ìƒ‰ ì¤‘: '{query}'")
    results = vector_store.similarity_search(query, k=3)
    
    context = "\n".join([f"- {doc.page_content} (ì¶œì²˜: {doc.metadata.get('source', 'unknown')})" for doc in results])
    return context

# ---------------------------------------------------------
# [Step 3] ì „ë¬¸ê°€ ë…¸ë“œ (Workers) - RAG ì ìš©ë¨!
# ---------------------------------------------------------
def nutrition_expert_node(state: AgentState):
    print("  ğŸ¥¦ [ì˜ì–‘ ì „ë¬¸ê°€] ê°€ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    last_message = state["messages"][-1].content
    
    # 1. ë¬¸ì„œ ê²€ìƒ‰
    context = retrieve_knowledge(last_message, "Nutrition")
    
    # 2. ë‹µë³€ ìƒì„± (Context ì£¼ì…)
    system_msg = (
        "ë‹¹ì‹ ì€ ì˜ì–‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì˜ [ê²€ìƒ‰ëœ ê°€ì´ë“œë¼ì¸]ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n"
        "ì¶œì²˜ë¥¼ ë°˜ë“œì‹œ ëª…ì‹œí•˜ì„¸ìš”.\n\n"
        f"[ê²€ìƒ‰ëœ ê°€ì´ë“œë¼ì¸]\n{context}"
    )
    
    response = llm.invoke([SystemMessage(content=system_msg)] + state["messages"])
    return {"messages": [response]}

def sleep_expert_node(state: AgentState):
    print("  ğŸ’¤ [ìˆ˜ë©´ ì „ë¬¸ê°€] ê°€ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    last_message = state["messages"][-1].content
    
    # 1. ë¬¸ì„œ ê²€ìƒ‰
    context = retrieve_knowledge(last_message, "Sleep")
    
    # 2. ë‹µë³€ ìƒì„±
    system_msg = (
        "ë‹¹ì‹ ì€ ìˆ˜ë©´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì˜ [ê²€ìƒ‰ëœ ê°€ì´ë“œë¼ì¸]ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n"
        "ì¶œì²˜ë¥¼ ë°˜ë“œì‹œ ëª…ì‹œí•˜ì„¸ìš”.\n\n"
        f"[ê²€ìƒ‰ëœ ê°€ì´ë“œë¼ì¸]\n{context}"
    )
    
    response = llm.invoke([SystemMessage(content=system_msg)] + state["messages"])
    return {"messages": [response]}

# ---------------------------------------------------------
# [Step 4] ê´€ë¦¬ì ë…¸ë“œ (Supervisor)
# ---------------------------------------------------------
def supervisor_node(state: AgentState):
    print("\nğŸ‘® [ê´€ë¦¬ì(GPT-4o)] ê°€ ì§ˆë¬¸ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")
    
    options = ["Nutrition_Expert", "Sleep_Expert"]
    
    system_prompt = (
        "ë‹¹ì‹ ì€ BabySquad íŒ€ì˜ ê´€ë¦¬ìì…ë‹ˆë‹¤."
        "ëŒ€í™” ë‚´ìš©ì„ ë³´ê³  ë‹¤ìŒ ì¤‘ ëˆ„êµ¬ì—ê²Œ ì—…ë¬´ë¥¼ ë°°ì •í• ì§€ ê²°ì •í•˜ì„¸ìš”: {options}."
        "ë‹µë³€ì€ ë°˜ë“œì‹œ ì „ë¬¸ê°€ì˜ ì´ë¦„ë§Œ ë§í•˜ì„¸ìš”."
    )
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="messages"),
    ]).partial(options=str(options))
    
    supervisor_chain = prompt | llm
    
    result = supervisor_chain.invoke(state["messages"])
    decision = result.content.strip()
    
    # ì•ˆì „ì¥ì¹˜
    if "Nutrition" in decision: decision = "Nutrition_Expert"
    elif "Sleep" in decision: decision = "Sleep_Expert"
    else: decision = "Nutrition_Expert"
        
    print(f"ğŸ‘‰ íŒë‹¨ ê²°ê³¼: '{decision}' ì—ê²Œ ë°°ì •í•©ë‹ˆë‹¤.")
    return {"next": decision}

# ---------------------------------------------------------
# [Step 5] ê·¸ë˜í”„ ì—°ê²° (Wiring)
# ---------------------------------------------------------
workflow = StateGraph(AgentState)

workflow.add_node("Supervisor", supervisor_node)
workflow.add_node("Nutrition_Expert", nutrition_expert_node)
workflow.add_node("Sleep_Expert", sleep_expert_node)

workflow.set_entry_point("Supervisor")

workflow.add_conditional_edges(
    "Supervisor",
    lambda state: state["next"],
    {
        "Nutrition_Expert": "Nutrition_Expert",
        "Sleep_Expert": "Sleep_Expert"
    }
)

workflow.add_edge("Nutrition_Expert", END)
workflow.add_edge("Sleep_Expert", END)

# [í•µì‹¬] ê¸°ì–µë ¥ ì¥ì°©! ğŸ§ 
memory = MemorySaver()
app = workflow.compile(checkpointer=memory)

def get_graph_app():
    return app
# ---------------------------------------------------------
# [Step 6] ëŒ€í™”í˜• ì‹¤í–‰ (Chat Loop)
# ---------------------------------------------------------
# if __name__ == "__main__":
#     from langchain_community.callbacks import get_openai_callback
    
#     # thread_id: ëŒ€í™” ì„¸ì…˜ì„ êµ¬ë¶„í•˜ëŠ” ID (ì´ê²Œ ê°™ìœ¼ë©´ ê¸°ì–µì„ ê³µìœ í•¨)
#     config = {"configurable": {"thread_id": "session_1"}}
    
#     print("========== BabySquad AI (Type 'quit' to exit) ==========")
    
#     while True:
#         user_input = input("\nğŸ§‘ ì‚¬ìš©ì: ")
#         if user_input.lower() in ["quit", "exit"]:
#             break
            
#         with get_openai_callback() as cb:
#             # invoke ëŒ€ì‹  streamì„ ì“°ë©´ í•œ ê¸€ìì”© ë‚˜ì˜¤ì§€ë§Œ, ì§€ê¸ˆì€ ê°„ë‹¨íˆ invoke
#             result = app.invoke(
#                 {"messages": [HumanMessage(content=user_input)]},
#                 config=config # ì„¤ì •(thread_id) ì „ë‹¬
#             )
#             print(f"ğŸ¤– AI: {result['messages'][-1].content}")
#             print(f"   (Cost: ${cb.total_cost:.5f})")